# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LsEM6_KbkG2PFaMfbFH9GxhjOAAGMk4Q
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
# 挂载 Google Drive
from google.colab import drive
drive.mount('/content/drive')

# 切换到项目目录 (请先把你的 codecarbon-master 上传到 Google Drive)
# %cd /content/drive/MyDrive/codecarbon-master

# 创建虚拟环境（可选，Colab 自带环境一般够用）
!pip install --upgrade pip
!pip install torch transformers codecarbon

import os

LOG_FILE = "logs/test_llm.jsonl"
os.makedirs("logs", exist_ok=True)

# 定义要跑的模型
gpt2_models = ["distilgpt2", "gpt2", "gpt2-medium", "gpt2-large", "gpt2-xl"]
llama_models = ["meta-llama/Llama-2-7b-hf"]   # ⚠️ 需要 HuggingFace 权限
falcon_models = ["tiiuae/falcon-7b"]

def run_cmd(cmd):
    print(f"\n===== Running: {cmd} =====")
    os.system(cmd)

# ----------------------------
# GPT-2 系列
# ----------------------------
for model in gpt2_models:
    run_cmd(f"python test_llm.py --mode infer --model_name {model} --repeats 5 --seq_len 128 --log_file {LOG_FILE}")
    run_cmd(f"python test_llm.py --mode infer --model_name {model} --repeats 5 --seq_len 512 --log_file {LOG_FILE}")
    run_cmd(f"python test_llm.py --mode train --model_name {model} --batch_size 2 --seq_len 128 --log_file {LOG_FILE}")

# ----------------------------
# LLaMA-2-7B
# ----------------------------
for model in llama_models:
    run_cmd(f"python test_llm.py --mode infer --model_name {model} --repeats 3 --seq_len 128 --log_file {LOG_FILE}")
    run_cmd(f"python test_llm.py --mode infer --model_name {model} --repeats 3 --seq_len 512 --log_file {LOG_FILE}")
    run_cmd(f"python test_llm.py --mode train --model_name {model} --batch_size 1 --seq_len 128 --log_file {LOG_FILE}")

# ----------------------------
# Falcon-7B
# ----------------------------
for model in falcon_models:
    run_cmd(f"python test_llm.py --mode infer --model_name {model} --repeats 3 --seq_len 128 --log_file {LOG_FILE}")
    run_cmd(f"python test_llm.py --mode infer --model_name {model} --repeats 3 --seq_len 512 --log_file {LOG_FILE}")
    run_cmd(f"python test_llm.py --mode train --model_name {model} --batch_size 1 --seq_len 128 --log_file {LOG_FILE}")

print("\n✅ 全部实验完成，结果已写入 logs/test_llm.jsonl 和 leaderboard.csv")

import os

LOG_FILE = "logs/test_llm.jsonl"
os.makedirs("logs", exist_ok=True)

# ----------------------------
# 要跑的 GPU 模型
# ----------------------------
gpu_models = {
    # 中等规模（~1B）
    "facebook/opt-1.3b": {"batch": 2},
    "EleutherAI/pythia-1b": {"batch": 2},
    "bigscience/bloom-1b1": {"batch": 1},

    # 大模型（7B 级）
    "mistralai/Mistral-7B-v0.1": {"batch": 1},
    "Qwen/Qwen-7B": {"batch": 1},
    "tiiuae/falcon-7b": {"batch": 1},
    "google/gemma-7b": {"batch": 1},  # 如果 HF 授权可用
}

def run_cmd(cmd):
    print(f"\n===== Running: {cmd} =====")
    os.system(cmd)

# ----------------------------
# 执行实验
# ----------------------------
for model, cfg in gpu_models.items():
    bs = cfg["batch"]

    # 推理：短序列
    run_cmd(
        f"python test_llm.py --mode infer --model_name {model} "
        f"--repeats 3 --seq_len 128 --batch_size {bs} "
        f"--dtype fp16 --log_file {LOG_FILE}"
    )

    # 推理：长序列
    run_cmd(
        f"python test_llm.py --mode infer --model_name {model} "
        f"--repeats 3 --seq_len 512 --batch_size {bs} "
        f"--dtype fp16 --log_file {LOG_FILE}"
    )

    # 训练：短序列
    run_cmd(
        f"python test_llm.py --mode train --model_name {model} "
        f"--seq_len 128 --batch_size {bs} --dtype fp16 "
        f"--log_file {LOG_FILE}"
    )

print("\n✅ GPU 实验完成，结果写入 logs/test_llm.jsonl")

import os, json

LOG_FILE = "logs/test_llm.jsonl"
os.makedirs("logs", exist_ok=True)

# ----------------------------
# 全部目标 GPU 模型
# ----------------------------
gpu_models = {
    "facebook/opt-1.3b": {"batch": 2},
    "EleutherAI/pythia-1b": {"batch": 2},
    "bigscience/bloom-1b1": {"batch": 1},
    "mistralai/Mistral-7B-v0.1": {"batch": 1},
    "Qwen/Qwen-7B": {"batch": 1},
    "tiiuae/falcon-7b": {"batch": 1},
    "google/gemma-7b": {"batch": 1},  # 如果 HF 授权可用
}

# ----------------------------
# 读取现有日志，看看哪些模型已经有结果
# ----------------------------
existing = set()
if os.path.exists(LOG_FILE):
    with open(LOG_FILE, "r", encoding="utf-8") as f:
        for line in f:
            try:
                rec = json.loads(line)
                if isinstance(rec, dict) and "model" in rec:
                    existing.add(rec["model"])
            except:
                continue

print("📊 日志中已有模型:", existing)

# ----------------------------
# 执行实验（只跑缺失的）
# ----------------------------
def run_cmd(cmd):
    print(f"\n===== Running: {cmd} =====")
    os.system(cmd)

for model, cfg in gpu_models.items():
    if model in existing:
        print(f"⏭️ 跳过 {model}（已有结果）")
        continue

    bs = cfg["batch"]
    print(f"\n🚀 开始补跑 {model}")

    # 推理：短序列
    run_cmd(
        f"python test_llm.py --mode infer --model_name {model} "
        f"--repeats 3 --seq_len 128 --batch_size {bs} "
        f"--dtype fp16 --log_file {LOG_FILE}"
    )

    # 推理：长序列
    run_cmd(
        f"python test_llm.py --mode infer --model_name {model} "
        f"--repeats 3 --seq_len 512 --batch_size {bs} "
        f"--dtype fp16 --log_file {LOG_FILE}"
    )

    # 训练：短序列
    run_cmd(
        f"python test_llm.py --mode train --model_name {model} "
        f"--seq_len 128 --batch_size {bs} --dtype fp16 "
        f"--log_file {LOG_FILE}"
    )

print("\n✅ GPU 补跑完成，结果写入 logs/test_llm.jsonl")

import os, json
from huggingface_hub import login

# ----------------------------
# 登录 Hugging Face（填入你的 token）
# ----------------------------


LOG_FILE = "logs/test_llm.jsonl"
os.makedirs("logs", exist_ok=True)

gpu_models = {
    "facebook/opt-1.3b": {"batch": 2},
    "EleutherAI/pythia-1b": {"batch": 2},
    "bigscience/bloom-1b1": {"batch": 1},
    "mistralai/Mistral-7B-v0.1": {"batch": 1},
    "tiiuae/falcon-7b": {"batch": 1},
    "google/gemma-7b": {"batch": 1},
}

def run_cmd(cmd):
    print(f"\n===== Running: {cmd} =====")
    os.system(cmd)

for model, cfg in gpu_models.items():
    bs = cfg["batch"]

    run_cmd(f"python test_llm.py --mode infer --model_name {model} "
            f"--repeats 3 --seq_len 128 --batch_size {bs} "
            f"--log_file {LOG_FILE}")

    run_cmd(f"python test_llm.py --mode infer --model_name {model} "
            f"--repeats 3 --seq_len 512 --batch_size {bs} "
            f"--log_file {LOG_FILE}")

    run_cmd(f"python test_llm.py --mode train --model_name {model} "
            f"--seq_len 128 --batch_size {bs} "
            f"--log_file {LOG_FILE}")

print("\n✅ GPU 实验完成，结果写入 logs/test_llm.jsonl")

import json
import pandas as pd

LOG_FILE = "logs/test_llm.jsonl"
LEADERBOARD_FIXED = "leaderboard_fixed.csv"

# 1. 读 JSONL
rows = []
with open(LOG_FILE, "r", encoding="utf-8") as f:
    for line in f:
        try:
            rec = json.loads(line)
            if isinstance(rec, dict):
                rows.append(rec)
        except:
            continue

df = pd.DataFrame(rows)
print("✅ 读入日志:", df.shape)

# 2. 加 device 列
cpu_models = ["distilgpt2", "gpt2", "gpt2-medium", "gpt2-large", "gpt2-xl"]
df["device"] = df["model"].apply(lambda m: "CPU" if m in cpu_models else "GPU")

# 3. 聚合（fixed 表）——同一配置取平均
group_keys = ["model","task","device"]
agg_dict = {}
for c in df.columns:
    if c not in group_keys:
        if pd.api.types.is_numeric_dtype(df[c]):
            agg_dict[c] = "mean"
        else:
            agg_dict[c] = "first"

df_fixed = df.groupby(group_keys, dropna=False).agg(agg_dict).reset_index()
df_fixed["runs_count"] = df.groupby(group_keys).size().values

# 4. 保存
df_fixed.to_csv(LEADERBOARD_FIXED, index=False)
print("✅ 已生成", LEADERBOARD_FIXED, "大小:", df_fixed.shape)
display(df_fixed.head())

import pandas as pd
import matplotlib.pyplot as plt

# 读取数据
df = pd.read_csv("leaderboard_fixed.csv")

# 模型参数规模 (单位: 参数个数)
param_counts = {
    "distilgpt2": 82e6,
    "gpt2": 124e6,
    "gpt2-medium": 355e6,
    "gpt2-large": 774e6,
    "gpt2-xl": 1.5e9,
    "facebook/opt-1.3b": 1.3e9,
    "EleutherAI/pythia-1b": 1e9,
    "bigscience/bloom-1b1": 1.1e9,
    "tiiuae/falcon-7b": 7e9,
    "mistralai/Mistral-7B-v0.1": 7e9,
    "google/gemma-7b": 7e9,
}
df["param_count"] = df["model"].map(param_counts)

# 绘制 CPU vs GPU 吞吐率
plt.figure(figsize=(8,6))
for device, group in df.groupby("device"):
    plt.plot(group["param_count"], group["tokens_per_s"], "o-", label=device)

plt.xscale("log")
plt.yscale("log")
plt.xlabel("Model size (parameters)")
plt.ylabel("Throughput (tokens/s)")
plt.title("Throughput vs Model Size (CPU vs GPU)")
plt.legend()
plt.grid(True, which="both", ls="--", alpha=0.6)
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.linear_model import LinearRegression

df = pd.read_csv("leaderboard_fixed.csv")

# 参数规模
param_counts = {
    "distilgpt2": 82e6,
    "gpt2": 124e6,
    "gpt2-medium": 355e6,
    "gpt2-large": 774e6,
    "gpt2-xl": 1.5e9,
    "facebook/opt-1.3b": 1.3e9,
    "EleutherAI/pythia-1b": 1e9,
    "bigscience/bloom-1b1": 1.1e9,
    "tiiuae/falcon-7b": 7e9,
    "mistralai/Mistral-7B-v0.1": 7e9,
    "google/gemma-7b": 7e9,
}
df["param_count"] = df["model"].map(param_counts)

# -------------------
# 图 1: 模型规模 vs 碳排放
# -------------------
plt.figure(figsize=(8,6))
for device, group in df.groupby("device"):
    plt.plot(group["param_count"], group["emissions"], "o-", label=device)
plt.xscale("log")
plt.yscale("log")
plt.xlabel("Model size (parameters)")
plt.ylabel("Emissions (kg CO₂e)")
plt.title("Model Size vs Emissions (CPU vs GPU)")
plt.legend()
plt.grid(True, which="both", ls="--", alpha=0.6)
plt.show()

# -------------------
# 图 2: 能效 vs 模型规模
# -------------------
df["efficiency"] = df["emissions"] / df["flops"]

plt.figure(figsize=(8,6))
for device, group in df.groupby("device"):
    plt.plot(group["param_count"], group["efficiency"], "o-", label=device)
plt.xscale("log")
plt.yscale("log")
plt.xlabel("Model size (parameters)")
plt.ylabel("Emissions per FLOP (kg CO₂e / FLOP)")
plt.title("Energy Efficiency vs Model Size")
plt.legend()
plt.grid(True, which="both", ls="--", alpha=0.6)
plt.show()

# -------------------
# 图 3: FLOPs vs 碳排放 (log-log 回归)
# -------------------
plt.figure(figsize=(8,6))
for device, group in df.groupby("device"):
    plt.scatter(group["flops"], group["emissions"], alpha=0.7, label=device)

# 回归拟合 (log-log)
X = np.log10(df["flops"].values.reshape(-1,1))
y = np.log10(df["emissions"].values)
reg = LinearRegression().fit(X, y)
x_fit = np.linspace(X.min(), X.max(), 100).reshape(-1,1)
y_fit = reg.predict(x_fit)
plt.plot(10**x_fit.flatten(), 10**y_fit, "k--", label=f"Trend slope={reg.coef_[0]:.2f}")

plt.xscale("log")
plt.yscale("log")
plt.xlabel("FLOPs")
plt.ylabel("Emissions (kg CO₂e)")
plt.title("FLOPs vs Emissions (log-log)")
plt.legend()
plt.grid(True, which="both", ls="--", alpha=0.6)
plt.show()

import pandas as pd
df = pd.read_csv("leaderboard_fixed.csv")
print(df.columns)

import pandas as pd
df = pd.read_csv("leaderboard_fixed.csv")
print(df["model"].unique())
print(len(df))

import pandas as pd

df = pd.read_csv("leaderboard_fixed.csv")
print(df.columns)

import pandas as pd

# 读取 fixed 版本的 leaderboard
df_fixed = pd.read_csv("leaderboard_fixed.csv")

print("✅ 读取成功，表格大小:", df_fixed.shape)
display(df_fixed.head())

import pandas as pd
import json
import os

# ====== 文件路径配置 ======
LOG_JSONL = "logs/test_llm.jsonl"         # 日志文件
LEADERBOARD_FIXED = "leaderboard_fixed.csv"  # 已有 fixed 表（不在 logs 下）

# ====== 1. 读已有 fixed 表 ======
if os.path.exists(LEADERBOARD_FIXED):
    df_fixed_old = pd.read_csv(LEADERBOARD_FIXED)
    print("✅ 读取原来的 fixed 表:", df_fixed_old.shape, "列:", df_fixed_old.columns.tolist())
else:
    df_fixed_old = pd.DataFrame()
    print("⚠️ 没有找到旧的 leaderboard_fixed.csv，将只用 log 生成新的。")

# ====== 2. 从 jsonl 读取新结果 ======
rows = []
if os.path.exists(LOG_JSONL):
    with open(LOG_JSONL, "r", encoding="utf-8") as f:
        for line in f:
            try:
                rec = json.loads(line)
                if rec.get("_record_type") == "result-summary":
                    rows.append(rec)
            except:
                continue
    df_new = pd.DataFrame(rows)
    print("✅ 从日志读到新结果:", df_new.shape, "列:", df_new.columns.tolist())
else:
    df_new = pd.DataFrame()
    print("⚠️ 没有找到 logs/test_llm.jsonl")

# ====== 3. 合并老的 fixed 表和新数据 ======
if not df_fixed_old.empty and not df_new.empty:
    df_all = pd.concat([df_fixed_old, df_new], ignore_index=True)
elif not df_fixed_old.empty:
    df_all = df_fixed_old.copy()
else:
    df_all = df_new.copy()

print("📊 合并后数据大小:", df_all.shape)

# ====== 4. 自动选择分组键 ======
possible_keys = ["model","mode","seq_len","batch_size","dtype","task"]
group_keys = [k for k in possible_keys if k in df_all.columns]
print("🔑 使用的分组键:", group_keys)

# ====== 5. 聚合：数值取平均，字符串取第一个 ======
agg_dict = {}
for c in df_all.columns:
    if c not in group_keys:
        if pd.api.types.is_numeric_dtype(df_all[c]):
            agg_dict[c] = "mean"
        else:
            agg_dict[c] = "first"

df_fixed_new = df_all.groupby(group_keys, dropna=False).agg(agg_dict).reset_index()
df_fixed_new["runs_count"] = df_all.groupby(group_keys).size().values

# ====== 6. 保存 ======
df_fixed_new.to_csv(LEADERBOARD_FIXED, index=False)
print("✅ 已更新", LEADERBOARD_FIXED, "新表大小:", df_fixed_new.shape)
display(df_fixed_new.head())

import pandas as pd
import json
import os

LOG_JSONL = "logs/test_llm.jsonl"
LEADERBOARD_FIXED = "leaderboard_fixed.csv"

# 1. 读取日志
rows = []
with open(LOG_JSONL, "r", encoding="utf-8") as f:
    for line in f:
        try:
            rec = json.loads(line)
            if rec.get("_record_type") == "result-summary":
                rows.append(rec)
        except:
            continue

df = pd.DataFrame(rows)
print("✅ 读入日志:", df.shape, "列:", df.columns.tolist())

# 2. 确定分组键（根据日志里实际字段自动挑选）
possible_keys = ["model","mode","seq_len","batch_size","dtype","task"]
group_keys = [k for k in possible_keys if k in df.columns]
print("🔑 使用分组键:", group_keys)

# 3. 聚合逻辑：数值列取平均，字符串列取第一个
agg_dict = {}
for c in df.columns:
    if c not in group_keys:
        if pd.api.types.is_numeric_dtype(df[c]):
            agg_dict[c] = "mean"
        else:
            agg_dict[c] = "first"

df_fixed = df.groupby(group_keys, dropna=False).agg(agg_dict).reset_index()
df_fixed["runs_count"] = df.groupby(group_keys).size().values

# 4. 保存为新的 leaderboard_fixed.csv
df_fixed.to_csv(LEADERBOARD_FIXED, index=False)
print("✅ 已生成新的", LEADERBOARD_FIXED, "大小:", df_fixed.shape)
display(df_fixed.head())

import pandas as pd
import json

LOG_JSONL = "logs/test_llm.jsonl"
LEADERBOARD_FIXED = "leaderboard_fixed.csv"

# 1. 读 JSONL
rows = []
with open(LOG_JSONL, "r", encoding="utf-8") as f:
    for line in f:
        try:
            rec = json.loads(line)
            if isinstance(rec, dict):
                rows.append(rec)
        except:
            continue

df = pd.DataFrame(rows)
print("✅ 读入日志:", df.shape, "列:", df.columns.tolist())

# 2. 确定分组键
possible_keys = ["model","task","mode","seq_len","batch_size","dtype"]
group_keys = [k for k in possible_keys if k in df.columns]
print("🔑 使用分组键:", group_keys)

# 3. 聚合逻辑：数值列取平均，字符串列取第一个
agg_dict = {}
for c in df.columns:
    if c not in group_keys:
        if pd.api.types.is_numeric_dtype(df[c]):
            agg_dict[c] = "mean"
        else:
            agg_dict[c] = "first"

df_fixed = df.groupby(group_keys, dropna=False).agg(agg_dict).reset_index()
df_fixed["runs_count"] = df.groupby(group_keys).size().values

# 4. 保存
df_fixed.to_csv(LEADERBOARD_FIXED, index=False)
print("✅ 已生成", LEADERBOARD_FIXED, "大小:", df_fixed.shape)
display(df_fixed.head())

import pandas as pd
import matplotlib.pyplot as plt

# 读取修复后的 leaderboard
df = pd.read_csv("leaderboard_fixed.csv")

# 给模型加上参数量（近似值，方便画 scaling law）
param_counts = {
    "distilgpt2": 82e6,
    "gpt2": 124e6,
    "gpt2-medium": 355e6,
    "gpt2-large": 774e6,
    "gpt2-xl": 1.5e9,
    "tiiuae/falcon-7b": 7e9,
}
df["params"] = df["model"].map(param_counts)

# 参数量 vs 能耗
plt.figure(figsize=(8,5))
for task in df["task"].unique():
    subset = df[df["task"] == task]
    plt.scatter(subset["params"], subset["emissions"], label=task, alpha=0.7)

plt.xscale("log")
plt.yscale("log")
plt.xlabel("Model Parameters (log scale)")
plt.ylabel("Energy Consumption (kWh, log scale)")
plt.title("Scaling Law: Params vs Energy")
plt.legend()
plt.show()

# FLOPs vs 能耗
plt.figure(figsize=(8,5))
plt.scatter(df["flops"], df["emissions"], c="red", alpha=0.7)
plt.xscale("log")
plt.yscale("log")
plt.xlabel("FLOPs (log scale)")
plt.ylabel("Energy Consumption (kWh, log scale)")
plt.title("FLOPs vs Energy Consumption")
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# 读取修复后的 leaderboard
df = pd.read_csv("leaderboard_fixed.csv")

# 模型参数量映射
param_counts = {
    "distilgpt2": 82e6,
    "gpt2": 124e6,
    "gpt2-medium": 355e6,
    "gpt2-large": 774e6,
    "gpt2-xl": 1.5e9,
    "tiiuae/falcon-7b": 7e9,
}
df["params"] = df["model"].map(param_counts)

plt.figure(figsize=(8,6))

# ===== GPT-2 系列 (推理曲线) =====
gpt2_models = ["distilgpt2", "gpt2", "gpt2-medium", "gpt2-large", "gpt2-xl"]

for task, color in zip(["inference-short", "inference-long"], ["#1f77b4", "#ff7f0e"]):
    subset = df[(df["task"] == task) & (df["model"].isin(gpt2_models))]
    subset = subset.sort_values("params")
    plt.plot(subset["params"], subset["emissions"], marker="o", color=color, linewidth=2.5, label=f"GPT-2 {task}")

# ===== Falcon-7B (对照点) =====
for task, color, marker in zip(["inference-short", "inference-long"], ["#1f77b4", "#ff7f0e"], ["^", "v"]):
    subset = df[(df["task"] == task) & (df["model"] == "tiiuae/falcon-7b")]
    plt.scatter(subset["params"], subset["emissions"], marker=marker, s=150, color=color, edgecolor="black", zorder=5)
    for _, row in subset.iterrows():
        plt.text(row["params"]*1.05, row["emissions"], "Falcon-7B", fontsize=10, weight="bold", color=color)

# ===== 训练任务 (背景散点) =====
train_subset = df[df["task"].str.contains("training")]
plt.scatter(train_subset["params"], train_subset["emissions"], alpha=0.4, color="gray", label="Training tasks")

# ===== 坐标 & 样式 =====
plt.xscale("log")
plt.yscale("log")
plt.xlabel("Model Parameters", fontsize=12)
plt.ylabel("Energy Consumption (kWh)", fontsize=12)
plt.title("Scaling Law: GPT-2 vs Falcon-7B", fontsize=14, weight="bold")

# 图例只保留三类
handles, labels = plt.gca().get_legend_handles_labels()
by_label = dict(zip(labels, handles))
plt.legend(by_label.values(), by_label.keys(), loc="upper left", frameon=False)

plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

df = pd.read_csv("leaderboard_fixed.csv")

plt.figure(figsize=(8,6))

for task in ["inference-short", "inference-long", "training-b2-s128"]:
    subset = df[df["task"] == task]
    x = subset["flops"].values
    y = subset["emissions"].values
    plt.scatter(x, y, label=f"{task} data")

    # log-log 回归
    log_x = np.log10(x)
    log_y = np.log10(y)
    coef = np.polyfit(log_x, log_y, 1)
    trend_y = np.polyval(coef, log_x)
    order = np.argsort(x)
    plt.plot(x[order], 10**trend_y[order], linewidth=2, label=f"{task} fit (slope={coef[0]:.2f})")

plt.xscale("log")
plt.yscale("log")
plt.xlabel("FLOPs")
plt.ylabel("Energy Consumption (kWh)")
plt.title("FLOPs vs Energy Consumption (Grouped Fits)")
plt.legend()
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

df = pd.read_csv("leaderboard_fixed.csv")

# 只保留大模型 (≥ gpt2-medium)
large_models = ["gpt2-medium", "gpt2-large", "gpt2-xl", "tiiuae/falcon-7b"]
df_large = df[df["model"].isin(large_models)]

plt.figure(figsize=(8,6))

# 绘制各任务拟合 + 数据点
colors = {"inference-short": "blue", "inference-long": "orange", "training-b2-s128": "green"}

for task in ["inference-short", "inference-long", "training-b2-s128"]:
    subset = df_large[df_large["task"] == task]
    x = subset["flops"].values
    y = subset["emissions"].values

    if len(x) < 3:
        continue

    plt.scatter(x, y, label=f"{task} data", color=colors[task], alpha=0.7)

    # log-log 回归
    log_x = np.log10(x)
    log_y = np.log10(y)
    coef = np.polyfit(log_x, log_y, 1)
    trend_y = np.polyval(coef, log_x)
    order = np.argsort(x)
    plt.plot(x[order], 10**trend_y[order], color=colors[task], linewidth=2,
             label=f"{task} fit (slope={coef[0]:.2f})")

# ===== slope=1 理想参考线 =====
x_ref = np.logspace(9, 14, 100)
y_ref = 1e-4 * (x_ref / x_ref[0])  # 起点归一化
plt.plot(x_ref, y_ref, "--", color="gray", linewidth=2, label="Ideal slope=1")

# 坐标轴 & 样式
plt.xscale("log")
plt.yscale("log")
plt.xlabel("FLOPs", fontsize=12)
plt.ylabel("Energy Consumption (kWh)", fontsize=12)
plt.title("FLOPs vs Energy Consumption (Grouped Fits + Ideal Line)", fontsize=14, weight="bold")
plt.legend()
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# 读取数据
df = pd.read_csv("leaderboard_fixed.csv")

# 筛选 inference-short 任务
subset = df[df["task"] == "inference-short"].copy()

# 每个 model + device 取平均能耗
subset = subset.groupby(["model", "device"])["emissions"].mean().reset_index()

# 画柱状图
plt.figure(figsize=(8,6))
colors = {"CPU": "red", "GPU": "blue"}

for device in ["CPU", "GPU"]:
    dev_data = subset[subset["device"] == device]
    plt.bar(dev_data["model"], dev_data["emissions"],
            color=colors[device], label=device)

plt.xticks(rotation=30, ha="right")
plt.yscale("log")
plt.ylabel("Energy Consumption (kWh)")
plt.title("CPU vs GPU Energy Comparison (Inference-Short)")
plt.legend()
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# 读取数据
df = pd.read_csv("leaderboard_fixed.csv")

# 模型参数规模
param_counts = {
    "distilgpt2": 82e6,
    "gpt2": 124e6,
    "gpt2-medium": 355e6,
    "gpt2-large": 774e6,
    "gpt2-xl": 1.5e9,
    "facebook/opt-1.3b": 1.3e9,
    "EleutherAI/pythia-1b": 1e9,
    "bigscience/bloom-1b1": 1.1e9,
    "tiiuae/falcon-7b": 7e9,
    "mistralai/Mistral-7B-v0.1": 7e9,
    "google/gemma-7b": 7e9,
}
df["param_count"] = df["model"].map(param_counts)

# 画图：每个 task 一条曲线
plt.figure(figsize=(8,6))
for task, group in df.groupby("task"):
    plt.scatter(group["param_count"], group["emissions"], label=task, alpha=0.8)

plt.xscale("log")
plt.yscale("log")
plt.xlabel("Model Parameters (log scale)")
plt.ylabel("Energy Consumption (kWh, log scale)")
plt.title("Scaling Law: Params vs Energy (Task-level)")
plt.legend()
plt.grid(True, which="both", ls="--", alpha=0.6)
plt.show()

import pandas as pd

# 读取 summary.csv
df = pd.read_csv("summary.csv")

# ====== 1. 定义模型规模 (参数量) ======
param_map = {
    "distilgpt2": "82M",
    "gpt2": "124M",
    "gpt2-medium": "355M",
    "gpt2-large": "774M",
    "gpt2-xl": "1.5B",
    "EleutherAI/pythia-1b": "1.0B",
    "facebook/opt-1.3b": "1.3B",
    "bigscience/bloom-1b1": "1.1B",
    "google/gemma-7b": "7B",
    "mistralai/Mistral-7B-v0.1": "7B",
    "tiiuae/falcon-7b": "7B"
}

# ====== 2. 增加 Params 列 ======
df["params"] = df["model"].map(param_map)

# ====== 3. 调整列顺序 ======
df = df[["model", "params", "device", "flops", "emissions", "efficiency", "runs"]]

# 保存新的 CSV
df.to_csv("summary_with_params.csv", index=False)

# ====== 4. 输出 LaTeX 表格 ======
latex_table = df.to_latex(
    index=False,
    float_format="%.2e",
    caption="Summary of benchmark results across models, parameters, and devices.",
    label="tab:summary"
)

with open("summary_with_params.tex", "w") as f:
    f.write(latex_table)

print("✅ 已生成 summary_with_params.csv 和 summary_with_params.tex")
print("\n📑 LaTeX 预览:\n")
print(latex_table)

import os
import json
import pandas as pd
from codecarbon import EmissionsTracker

# ====== 1. 跑 CodeCarbon ======
def run_codecarbon(model_name, seq_len=128, repeats=3):
    log_file = f"logs/codecarbon_{model_name}_s{seq_len}.json"
    tracker = EmissionsTracker(output_file=log_file)
    tracker.start()

    # 调用你的 benchmark 脚本 (只跑 inference)
    os.system(f"python test_llm.py --mode infer --model_name {model_name} "
              f"--seq_len {seq_len} --repeats {repeats} --log_file {log_file}")

    emissions = tracker.stop()
    print(f"Model {model_name}, seq_len={seq_len} → {emissions:.4e} kgCO₂e")
    return emissions

# 示例：跑 GPT-2 和 Falcon-7B
models_to_test = [
    ("gpt2", 128),
    ("gpt2", 512),
    ("tiiuae/falcon-7b", 128),
    ("tiiuae/falcon-7b", 512),
]

results_cc = []
for model, seq in models_to_test:
    e = run_codecarbon(model, seq_len=seq, repeats=3)
    results_cc.append({"model": model, "task": f"inference-s{seq}", "device": "GPU", "CodeCarbon": e})

df_cc = pd.DataFrame(results_cc)

# ====== 2. 读取你自己的 benchmark ======
df_bench = pd.read_csv("leaderboard_fixed.csv")

# 只保留 inference-GPU 部分
df_bench = df_bench[df_bench["device"]=="GPU"]

# ====== 3. 匹配模型+任务，生成对比表 ======
df_compare = pd.merge(df_cc, df_bench, on=["model","task","device"], how="inner")

# 重命名列
df_compare = df_compare.rename(columns={"emissions": "OurBenchmark"})

# 计算差异
df_compare["Delta_%"] = (df_compare["OurBenchmark"] - df_compare["CodeCarbon"]) / df_compare["CodeCarbon"] * 100

# ====== 4. 保存 CSV + LaTeX ======
df_compare.to_csv("compare_codecarbon.csv", index=False)

latex_table = df_compare[["model","task","device","CodeCarbon","OurBenchmark","Delta_%"]].to_latex(
    index=False,
    float_format="%.2e",
    caption="Comparison of CodeCarbon vs Our Benchmark (GPU Inference).",
    label="tab:compare_codecarbon"
)
with open("compare_codecarbon.tex", "w") as f:
    f.write(latex_table)

print("✅ 已生成 compare_codecarbon.csv 和 compare_codecarbon.tex")
print(df_compare)

import os
import pandas as pd
from codecarbon import EmissionsTracker

# 确保 logs 目录存在
LOG_FILE = "logs/test_llm.jsonl"
os.makedirs("logs", exist_ok=True)

def run_codecarbon(model_name, mode="infer", seq_len=128, batch_size=1, repeats=3):
    """
    用 CodeCarbon 跑一次实验，返回 emissions
    """
    tracker = EmissionsTracker(
        output_dir="logs",
        output_file="cc_emissions.csv"   # ✅ 改成固定文件，不要 None
    )
    tracker.start()

    # 构建命令
    if mode == "infer":
        cmd = (
            f"python test_llm.py --mode infer --model_name {model_name} "
            f"--seq_len {seq_len} --repeats {repeats} --batch_size {batch_size} "
            f"--log_file {LOG_FILE}"
        )
    else:
        cmd = (
            f"python test_llm.py --mode train --model_name {model_name} "
            f"--seq_len {seq_len} --batch_size {batch_size} "
            f"--log_file {LOG_FILE}"
        )

    print(f"\n===== Running with CodeCarbon: {cmd} =====")
    os.system(cmd)

    emissions = tracker.stop()
    if emissions is None:
        emissions = 0.0

    print(f"[CodeCarbon] {model_name}, {mode}, seq={seq_len}, batch={batch_size} → {emissions:.4e} kgCO₂e")
    return emissions


# -----------------------------
# 要测试的模型 & 配置
# -----------------------------
tasks_to_test = [
    ("gpt2", "infer", 128, 1),
    ("gpt2", "train", 128, 1),
    ("gpt2-medium", "infer", 128, 1),
    ("tiiuae/falcon-7b", "infer", 128, 1),
]

# -----------------------------
# 循环跑实验 & 保存结果
# -----------------------------
results_cc = []

for model, mode, seq, batch in tasks_to_test:
    e = run_codecarbon(model, mode=mode, seq_len=seq, batch_size=batch, repeats=3)
    results_cc.append({
        "model": model,
        "mode": mode,
        "seq_len": seq,
        "batch_size": batch,
        "device": "GPU",
        "CodeCarbon_emissions": e
    })

# 保存到 DataFrame
df_cc = pd.DataFrame(results_cc)
df_cc.to_csv("results_codecarbon.csv", index=False)

print("\n✅ CodeCarbon 实验完成，结果写入 results_codecarbon.csv")
display(df_cc)

import pandas as pd

# 1. 读取两个文件
df_my = pd.read_csv("leaderboard_fixed.csv")
df_cc = pd.read_csv("results_codecarbon.csv")

# 2. 转换 CodeCarbon 的 task 名称为统一格式
def format_task(row):
    if row["mode"] == "infer":
        return f"inference-s{row['seq_len']}"
    else:
        return f"train-s{row['seq_len']}-b{row['batch_size']}"

df_cc["task"] = df_cc.apply(format_task, axis=1)

# 3. 保留需要的列
df_my_small = df_my[["model","task","device","emissions"]].rename(columns={"emissions":"My_emissions"})
df_cc_small = df_cc[["model","task","device","CodeCarbon_emissions"]]

# 4. 合并
df_compare = pd.merge(df_my_small, df_cc_small, on=["model","task","device"], how="inner")

# 5. 计算差异
df_compare["Diff_%"] = (df_compare["My_emissions"] - df_compare["CodeCarbon_emissions"]) / df_compare["CodeCarbon_emissions"] * 100

# 6. 保存 CSV
df_compare.to_csv("compare_my_vs_codecarbon.csv", index=False)

# 7. 生成 LaTeX 表格
latex_table = df_compare.to_latex(
    index=False,
    float_format="%.2e",
    caption="Comparison of CodeCarbon vs Our Benchmark",
    label="tab:compare_codecarbon"
)
with open("compare_my_vs_codecarbon.tex","w") as f:
    f.write(latex_table)

print("✅ 已生成 compare_my_vs_codecarbon.csv 和 compare_my_vs_codecarbon.tex")
print(df_compare)

import os
import pandas as pd
from codecarbon import EmissionsTracker

# 1. 读取 leaderboard
df = pd.read_csv("leaderboard_fixed.csv")
df_gpu = df[df["device"].str.upper() == "GPU"].copy()

# 2. 解析 task → (mode, seq_len, batch_size)
def parse_task(task):
    if task.startswith("inference"):
        mode = "infer"
        if "short" in task:
            seq_len = 128
        elif "long" in task:
            seq_len = 512
        else:
            seq_len = 128
        batch_size = 1
    elif task.startswith("training"):
        mode = "train"
        parts = task.split("-")
        b = [p for p in parts if p.startswith("b")]
        s = [p for p in parts if p.startswith("s")]
        batch_size = int(b[0][1:]) if b else 1
        seq_len = int(s[0][1:]) if s else 128
    else:
        mode, seq_len, batch_size = "infer", 128, 1
    return mode, seq_len, batch_size

df_gpu[["mode", "seq_len", "batch_size"]] = df_gpu.apply(
    lambda row: parse_task(row["task"]), axis=1, result_type="expand"
)

# 3. CodeCarbon runner
def run_codecarbon(model, mode, seq_len, batch_size, repeats=1):
    tracker = EmissionsTracker(output_dir=".", output_file="cc_tmp.csv", measure_power_secs=1)
    tracker.start()
    cmd = (
        f"python test_llm.py --mode {mode} "
        f"--model_name {model} --seq_len {seq_len} "
        f"--batch_size {batch_size} --repeats {repeats} --log_file cc_tmp.jsonl"
    )
    print(f"\n===== Running: {cmd} =====")
    os.system(cmd)
    emissions = tracker.stop()
    return emissions

# 4. 遍历 GPU 实验组合
results = []
for _, row in df_gpu.iterrows():
    model = row["model"]
    mode, seq_len, batch_size = row["mode"], row["seq_len"], row["batch_size"]
    e = run_codecarbon(model, mode, seq_len, batch_size, repeats=3)
    results.append({
        "model": model,
        "task": row["task"],
        "device": "GPU",
        "seq_len": seq_len,
        "batch_size": batch_size,
        "emissions_codecarbon": e
    })

# 5. 保存结果
df_cc = pd.DataFrame(results)
df_cc.to_csv("results_codecarbon_gpu.csv", index=False)
print("✅ CodeCarbon GPU 结果已保存到 results_codecarbon_gpu.csv")
display(df_cc.head())

import pandas as pd

# 1. 读取两个表
df_my = pd.read_csv("leaderboard_fixed.csv")
df_cc = pd.read_csv("results_codecarbon_gpu.csv")

# 2. 统一大小写
for col in ["model", "task", "device"]:
    df_my[col] = df_my[col].astype(str).str.strip().str.lower()
    df_cc[col] = df_cc[col].astype(str).str.strip().str.lower()

# 3. 修复 task 不一致的问题
# 以 benchmark (df_my) 的 task 为标准
valid_tasks = set(df_my["task"].unique())

# 如果 CodeCarbon 的 task 不在 benchmark 里，尝试映射
task_map = {
    "training-b1-s128": "training-b2-s128",  # ⚠️ 你需要确认 benchmark 是 b2
    # 其他不一致可以在这里加
}

df_cc["task"] = df_cc["task"].replace(task_map)

# 4. 选取必要字段
col_my = [c for c in df_my.columns if "emission" in c.lower()][0]
col_cc = [c for c in df_cc.columns if "emission" in c.lower()][0]

df_my_sel = df_my[["model", "task", "device", col_my]].rename(columns={col_my: "emissions_mine"})
df_cc_sel = df_cc[["model", "task", "device", col_cc]].rename(columns={col_cc: "emissions_codecarbon"})

# 5. 合并 (inner = 只对比重叠)
df_compare = pd.merge(df_my_sel, df_cc_sel, on=["model", "task", "device"], how="inner")

# 6. 差异计算
df_compare["diff"] = df_compare["emissions_mine"] - df_compare["emissions_codecarbon"]
df_compare["diff_pct"] = df_compare["diff"] / df_compare["emissions_codecarbon"] * 100

# 7. 保存结果
df_compare.to_csv("compare_my_vs_codecarbon.csv", index=False)
with open("compare_my_vs_codecarbon.tex", "w") as f:
    f.write(df_compare.to_latex(index=False, float_format="%.4e"))

print("✅ 对比表已生成: compare_my_vs_codecarbon.csv / .tex")
display(df_compare.head(20))

import pandas as pd

# 读两个表
df_my = pd.read_csv("leaderboard_fixed.csv")
df_cc = pd.read_csv("results_codecarbon.csv")

# ---- 1. 标准化 emissions 列 ----
def find_emissions_col(df):
    for c in df.columns:
        if "emission" in c.lower():   # 自动找包含 emission 的列
            return c
    raise ValueError("没有找到 emissions 列")

col_my = find_emissions_col(df_my)
col_cc = find_emissions_col(df_cc)

df_my_sel = df_my[["model", "task", "device", col_my]].rename(columns={col_my: "emissions_mine"})
df_cc_sel = df_cc[["model", "task", "device", col_cc]].rename(columns={col_cc: "emissions_codecarbon"})

# ---- 2. 合并 (只保留重叠部分) ----
df_compare = pd.merge(
    df_my_sel,
    df_cc_sel,
    on=["model", "task", "device"],
    how="inner"   # 改成 inner
)

# ---- 3. 计算差异 ----
df_compare["diff"] = df_compare["emissions_mine"] - df_compare["emissions_codecarbon"]
df_compare["diff_pct"] = df_compare["diff"] / df_compare["emissions_codecarbon"] * 100

# ---- 4. 保存结果 ----
df_compare.to_csv("compare_my_vs_codecarbon.csv", index=False)
with open("compare_my_vs_codecarbon.tex", "w") as f:
    f.write(df_compare.to_latex(index=False, float_format="%.4e"))

print("✅ 对比表生成完成 (只含重叠部分): compare_my_vs_codecarbon.csv / .tex")
display(df_compare.head(20))

keys_my = set(zip(df_my_sel["model"], df_my_sel["task"], df_my_sel["device"]))
keys_cc = set(zip(df_cc_sel["model"], df_cc_sel["task"], df_cc_sel["device"]))

print("我的表 key 样例:", list(keys_my)[:10])
print("CodeCarbon key 样例:", list(keys_cc)[:10])

print("重叠数量:", len(keys_my & keys_cc))
print("我的有但 CodeCarbon 没有:", len(keys_my - keys_cc))
print("CodeCarbon 有但我的没有:", len(keys_cc - keys_my))

import pandas as pd

df_compare = pd.read_csv("compare_my_vs_codecarbon.csv")

# 转换为 LaTeX
latex_table = df_compare.to_latex(
    index=False,
    float_format="%.2e",
    caption="Comparison of emissions: Our method vs CodeCarbon",
    label="tab:compare_emissions"
)

with open("compare_my_vs_codecarbon.tex", "w") as f:
    f.write(latex_table)

print("✅ 已生成 LaTeX 表格 → compare_my_vs_codecarbon.tex")
print(latex_table)

# Scaling Law
plt.figure(figsize=(8,6))
for task in df["task"].unique():
    subset = df[df["task"] == task]
    plt.scatter(subset["params"], subset["emissions"], label=task, alpha=0.7)
plt.xscale("log"); plt.yscale("log")
plt.xlabel("Model Parameters")
plt.ylabel("Energy Consumption (kWh)")
plt.title("Scaling Law: Params vs Energy", fontsize=14, fontweight="normal")
plt.legend()
plt.tight_layout()
plt.savefig("scaling_law.png", dpi=300)

# FLOPs vs Energy (Grouped Fits)
plt.figure(figsize=(8,6))
for task in ["inference-short", "inference-long", "training-b2-s128"]:
    subset = df[df["task"] == task]
    if len(subset) > 2:
        plt.scatter(subset["flops"], subset["emissions"], alpha=0.6, label=f"{task} data")
        log_x, log_y = np.log10(subset["flops"]), np.log10(subset["emissions"])
        coef = np.polyfit(log_x, log_y, 1)
        trend_y = np.polyval(coef, log_x)
        order = np.argsort(subset["flops"])
        plt.plot(subset["flops"].values[order], 10**trend_y[order], linewidth=2,
                 label=f"{task} fit (slope={coef[0]:.2f})")
plt.xscale("log"); plt.yscale("log")
plt.xlabel("FLOPs")
plt.ylabel("Energy Consumption (kWh)")
plt.title("FLOPs vs Energy (Grouped Fits)", fontsize=14, fontweight="normal")
plt.legend()
plt.tight_layout()
plt.savefig("flops_grouped.png", dpi=300)

# FLOPs vs Energy (Ideal Line)
plt.figure(figsize=(8,6))
for task in ["inference-short", "inference-long", "training-b2-s128"]:
    subset = df[df["task"] == task]
    if len(subset) > 2:
        plt.scatter(subset["flops"], subset["emissions"], alpha=0.6, label=f"{task} data")
        log_x, log_y = np.log10(subset["flops"]), np.log10(subset["emissions"])
        coef = np.polyfit(log_x, log_y, 1)
        trend_y = np.polyval(coef, log_x)
        order = np.argsort(subset["flops"])
        plt.plot(subset["flops"].values[order], 10**trend_y[order], linewidth=2,
                 label=f"{task} fit (slope={coef[0]:.2f})")
# 理想 slope=1
x_ref = np.logspace(9, 14, 100)
y_ref = 1e-4 * (x_ref / x_ref[0])
plt.plot(x_ref, y_ref, "--", color="gray", linewidth=2, label="Ideal slope=1")
plt.xscale("log"); plt.yscale("log")
plt.xlabel("FLOPs")
plt.ylabel("Energy Consumption (kWh)")
plt.title("FLOPs vs Energy (Ideal Line)", fontsize=14, fontweight="normal")
plt.legend()
plt.tight_layout()
plt.savefig("flops_ideal.png", dpi=300)

# CPU vs GPU
plt.figure(figsize=(8,6))
subset = df[df["task"] == "inference-short"]
models = subset["model"].unique()
for i, model in enumerate(models):
    model_data = subset[subset["model"] == model]
    cpu_val = model_data[model_data["device"] == "CPU"]["emissions"].mean()
    gpu_val = model_data[model_data["device"] == "GPU"]["emissions"].mean()
    if not pd.isna(cpu_val):
        plt.bar(i-0.2, cpu_val, width=0.4, color="red", alpha=0.7, label="CPU" if i==0 else "")
    if not pd.isna(gpu_val):
        plt.bar(i+0.2, gpu_val, width=0.4, color="blue", alpha=0.7, label="GPU" if i==0 else "")
plt.xticks(range(len(models)), models, rotation=30)
plt.yscale("log")
plt.ylabel("Energy Consumption (kWh)")
plt.title("CPU vs GPU Energy Comparison", fontsize=14, fontweight="normal")
plt.legend()
plt.tight_layout()
plt.savefig("cpu_vs_gpu.png", dpi=300)

# 模型参数规模（估算值）
param_counts = {
    "distilgpt2": 82e6,
    "gpt2": 124e6,
    "gpt2-medium": 355e6,
    "gpt2-large": 774e6,
    "gpt2-xl": 1.5e9,
    "tiiuae/falcon-7b": 7e9,
}

# 新增列 'params'
df["params"] = df["model"].map(param_counts)

import json
import pandas as pd

# 从日志读取
records = []
with open("logs/test_llm.jsonl", "r") as f:
    for line in f:
        try:
            records.append(json.loads(line.strip()))
        except:
            continue

df_log = pd.DataFrame(records)

# 如果没有 device 字段，用模型名推断
if "device" not in df_log.columns:
    def assign_device(model):
        big_models = ["gpt2-large", "gpt2-xl", "tiiuae/falcon-7b", "meta-llama/Llama-2-7b-hf"]
        if any(b in model for b in big_models):
            return "GPU"
        else:
            return "CPU"
    df_log["device"] = df_log["model"].apply(assign_device)

# 保留主要字段
cols_to_keep = ["model", "task", "flops", "accuracy", "emissions", "device", "timestamp"]
for col in cols_to_keep:
    if col not in df_log.columns:
        df_log[col] = None

df_log = df_log[cols_to_keep]

# 保存新 leaderboard
df_log.to_csv("leaderboard_fixed.csv", index=False)

print("✅ 已重建 leaderboard_fixed.csv，CPU/GPU 已区分")
print(df_log["device"].value_counts())

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# 读取数据
df = pd.read_csv("leaderboard_fixed.csv")

# 只看 inference-short
df_filtered = df[df["task"]=="inference-short"]

# 按模型+设备分组
avg_energy = df_filtered.groupby(["model","device"])["emissions"].mean().unstack(fill_value=np.nan)

# 指定模型顺序（把 GPT 系列放一起，Falcon 放最后）
model_order = ["distilgpt2","gpt2","gpt2-medium","gpt2-large","gpt2-xl","tiiuae/falcon-7b"]
avg_energy = avg_energy.reindex(model_order)

# 画图
x = np.arange(len(avg_energy))
width = 0.35

plt.figure(figsize=(8,6))
plt.bar(x - width/2, avg_energy["CPU"], width, color="red", label="CPU")
plt.bar(x + width/2, avg_energy["GPU"], width, color="blue", label="GPU")

plt.xticks(x, avg_energy.index, rotation=45)
plt.yscale("log")
plt.ylabel("Energy Consumption (kWh)")
plt.title("CPU vs GPU Energy Comparison (Inference-Short)", fontsize=14, fontweight="normal")
plt.legend()
plt.tight_layout()
plt.savefig("cpu_vs_gpu_aligned.png", dpi=300)
plt.show()

# 只选 GPU 的数据
df_gpu = df[df["device"] == "GPU"]

plt.figure(figsize=(8,6))
colors = {"inference-short": "blue", "inference-long": "orange"}
for task, color in colors.items():
    subset = df_gpu[df_gpu["task"] == task]
    if len(subset) > 2:
        plt.scatter(subset["flops"], subset["emissions"], color=color, alpha=0.6, label=f"{task} data")
        log_x, log_y = np.log10(subset["flops"]), np.log10(subset["emissions"])
        coef = np.polyfit(log_x, log_y, 1)
        trend_y = np.polyval(coef, log_x)
        order = np.argsort(subset["flops"])
        plt.plot(subset["flops"].values[order], 10**trend_y[order], color=color, linewidth=2,
                 label=f"{task} fit (slope={coef[0]:.2f})")

# 理想 slope=1
x_ref = np.logspace(9, 14, 100)
y_ref = 1e-4 * (x_ref / x_ref[0])
plt.plot(x_ref, y_ref, "--", color="gray", linewidth=2, label="Ideal slope=1")

plt.xscale("log"); plt.yscale("log")
plt.xlabel("FLOPs")
plt.ylabel("Energy Consumption (kWh)")
plt.title("FLOPs vs Energy (GPU only)", fontsize=14, fontweight="normal")
plt.legend()
plt.tight_layout()
plt.savefig("flops_vs_energy_gpu.png", dpi=300)
plt.show()

plt.figure(figsize=(8,6))

# GPT-2 系列
for task, marker in {"inference-short":"o", "inference-long":"s"}.items():
    subset = df_focus[(df_focus["model"].isin(gpt2_models)) & (df_focus["task"]==task)].sort_values("flops")
    plt.plot(subset["flops"], subset["emissions"],
             marker=marker, linestyle="-", color="blue", markersize=6,
             label=f"GPT-2 {task}")

# Falcon-7B
for task, marker in {"inference-short":"o", "inference-long":"s"}.items():
    falcon = df_focus[(df_focus["model"]=="tiiuae/falcon-7b") & (df_focus["task"]==task)]
    if len(falcon) > 0:
        plt.scatter(falcon["flops"], falcon["emissions"],
                    color="orange", edgecolor="black", marker=marker, s=120,
                    label=f"Falcon-7B {task}")

plt.xscale("log"); plt.yscale("log")
plt.xlabel("Model Parameters / FLOPs (log scale)")
plt.ylabel("Energy Consumption (kWh, log scale)")
plt.title("Scaling Law: GPT-2 vs Falcon-7B", fontsize=14, fontweight="normal")
plt.legend()
plt.tight_layout()
plt.savefig("scaling_gpt2_vs_falcon_final.png", dpi=300)
plt.show()

!pip install transformers bitsandbytes pynvml accelerate matplotlib

import torch
from torch.utils.data import DataLoader
from transformers import AutoModelForCausalLM, AutoTokenizer, Adafactor
from torch.optim import AdamW
import bitsandbytes as bnb
import pynvml
import time, csv
import matplotlib.pyplot as plt


# ----------------------------
# GPU 功耗监控
# ----------------------------
def init_nvml():
    pynvml.nvmlInit()
    handle = pynvml.nvmlDeviceGetHandleByIndex(0)
    return handle

def get_power(handle):
    return pynvml.nvmlDeviceGetPowerUsage(handle) / 1000.0  # W


# ----------------------------
# 训练过程
# ----------------------------
def train(args):
    tokenizer = AutoTokenizer.from_pretrained(args.model)
    if tokenizer.pad_token is None:  # ✅ 解决 GPT2 没有 pad_token 的问题
        tokenizer.pad_token = tokenizer.eos_token

    model = AutoModelForCausalLM.from_pretrained(
        args.model,
        torch_dtype=torch.float32 if args.precision == "fp32" else torch.bfloat16,
        device_map="auto"
    )

    texts = ["Hello world!"] * 256
    encodings = tokenizer(texts, return_tensors="pt", padding=True, truncation=True)
    dataset = torch.utils.data.TensorDataset(encodings["input_ids"], encodings["attention_mask"])
    dataloader = DataLoader(dataset, batch_size=4)

    # 选择优化器
    if args.optimizer == "adam":
        optimizer = AdamW(model.parameters(), lr=5e-5)
    elif args.optimizer == "adafactor":
        optimizer = Adafactor(model.parameters(), scale_parameter=True, relative_step=True, warmup_init=True, lr=None)
    elif args.optimizer == "lamb":
        optimizer = bnb.optim.LAMB(model.parameters(), lr=5e-5)
    else:
        raise ValueError(f"Unsupported optimizer: {args.optimizer}")

    handle = init_nvml()
    total_energy = 0.0

    log_file = f"log_train_{args.model}_{args.optimizer}_{args.precision}.csv"
    with open(log_file, "w", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(["step", "loss", "power_watt", "energy_joule"])

        model.train()
        for step, batch in enumerate(dataloader):
            inputs = {
                "input_ids": batch[0].to(model.device),
                "attention_mask": batch[1].to(model.device),
                "labels": batch[0].to(model.device),
            }

            power = get_power(handle)
            start = time.time()

            outputs = model(**inputs)
            loss = outputs.loss
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()

            duration = time.time() - start
            total_energy += power * duration

            writer.writerow([step, loss.item(), power, total_energy])

            if step % 10 == 0:
                print(f"[Train] Step {step} | Loss {loss.item():.4f} | Power {power:.2f} W | Energy {total_energy:.2f} J")

    print(f"训练完成，总能耗: {total_energy:.2f} J")
    return model, tokenizer


# ----------------------------
# 推理测试
# ----------------------------
def inference(args, model, tokenizer):
    handle = init_nvml()
    total_energy = 0.0
    total_tokens = 0

    prompts = ["The quick brown fox jumps over the lazy dog."] * 10

    log_file = f"log_infer_{args.model}_{args.optimizer}_{args.precision}.csv"
    with open(log_file, "w", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(["sample_id", "power_watt", "duration_sec", "energy_joule", "tokens"])

        for i, text in enumerate(prompts):
            inputs = tokenizer(text, return_tensors="pt").to(model.device)

            power = get_power(handle)
            start = time.time()

            outputs = model.generate(**inputs, max_new_tokens=50)
            duration = time.time() - start
            tokens = outputs.shape[1] - inputs["input_ids"].shape[1]

            energy = power * duration
            total_energy += energy
            total_tokens += tokens

            writer.writerow([i, power, duration, energy, tokens])
            print(f"[Infer] Sample {i} | Tokens {tokens} | Power {power:.2f} W | Energy {energy:.2f} J")

    avg_j_per_token = total_energy / total_tokens
    print(f"推理完成: 总能耗 {total_energy:.2f} J, 总tokens {total_tokens}, 平均 {avg_j_per_token:.6f} J/token")

class Args:
    model = "gpt2"
    precision = "fp32"   # fp32 / bf16
    optimizer = "adam"   # adam / adafactor / lamb

args = Args()
args.model = "gpt2"
args.precision = "fp32"
args.optimizer = "adam"

model, tokenizer = train(args)
inference(args, model, tokenizer)

results = []

for optimizer in ["adam", "adafactor"]:
    for precision in ["fp32", "bf16"]:
        args = Args()
        args.model = "gpt2"
        args.optimizer = optimizer
        args.precision = precision
        print(f"\n==== Running {optimizer} {precision} ====")
        model, tokenizer = train(args)
        inference(args, model, tokenizer)

import pandas as pd
import glob

# 收集训练日志
train_logs = glob.glob("log_train_*.csv")
infer_logs = glob.glob("log_infer_*.csv")

summary = []

for log in train_logs:
    df = pd.read_csv(log)
    total_energy = df["energy_joule"].iloc[-1]
    parts = log.replace("log_train_", "").replace(".csv", "").split("_")
    model, optimizer, precision = parts[0], parts[1], parts[2]
    summary.append({
        "Model": model,
        "Optimizer": optimizer,
        "Precision": precision,
        "Train Energy (J)": total_energy
    })

for log in infer_logs:
    df = pd.read_csv(log)
    total_energy = df["energy_joule"].sum()
    tokens = df["tokens"].sum()
    avg_j_token = total_energy / tokens
    parts = log.replace("log_infer_", "").replace(".csv", "").split("_")
    model, optimizer, precision = parts[0], parts[1], parts[2]
    for row in summary:
        if row["Optimizer"] == optimizer and row["Precision"] == precision:
            row["Infer Energy (J)"] = total_energy
            row["Avg J/token"] = avg_j_token

df_summary = pd.DataFrame(summary)
print(df_summary)

# 输出 LaTeX 表格
print(df_summary.to_latex(index=False, float_format="%.4f"))

import pandas as pd
import matplotlib.pyplot as plt

def plot_energy(log_files, title="Training Energy Consumption Curve"):
    fig, ax = plt.subplots()
    for log in log_files:
        df = pd.read_csv(log)
        label = log.replace("log_", "").replace(".csv", "")
        ax.plot(df["step"], df["energy_joule"], label=label)
    ax.set_xlabel("Training Step")
    ax.set_ylabel("Energy (J)")
    ax.set_title(title)   # ✅ English title
    ax.legend(title="Configuration")  # ✅ English legend title
    plt.show()

# Example call
plot_energy([
    "log_train_gpt2_adam_fp32.csv",
    "log_train_gpt2_adam_bf16.csv",
    "log_train_gpt2_adafactor_fp32.csv",
    "log_train_gpt2_adafactor_bf16.csv"
], title="GPT-2 Training Energy Consumption (Optimizer × Precision)")
import pandas as pd
import matplotlib.pyplot as plt

import pandas as pd
import matplotlib.pyplot as plt

# Example summary data
data = {
    "Optimizer": ["adam", "adam", "adafactor", "adafactor"],
    "Precision": ["bf16", "fp32", "fp32", "bf16"],
    "Avg J/token": [0.591230, 0.652791, 0.611825, 0.574222]
}
df_summary = pd.DataFrame(data)

# Pivot table for grouped bar plot
df_pivot = df_summary.pivot(index="Optimizer", columns="Precision", values="Avg J/token")

# Plot grouped bar chart
ax = df_pivot.plot(kind="bar", figsize=(6,5))
ax.set_title("GPT-2 Inference Energy per Token (Optimizer × Precision)")
ax.set_ylabel("Energy (J/token)")
ax.set_xlabel("Optimizer")
plt.xticks(rotation=0)
plt.legend(title="Precision")
plt.tight_layout()
plt.show()

!pip install transformers bitsandbytes pynvml accelerate fvcore

import torch, time, csv
import pynvml
from transformers import AutoModelForCausalLM, AutoTokenizer
from fvcore.nn import FlopCountAnalysis

from huggingface_hub import login


!pip install transformers bitsandbytes pynvml accelerate fvcore matplotlib

import os, torch, time, csv, pynvml
from transformers import AutoModelForCausalLM, AutoTokenizer
from fvcore.nn import FlopCountAnalysis
from huggingface_hub import login
import matplotlib.pyplot as plt
import pandas as pd

# ----------------------------
# 登录 HuggingFace（安全：从环境变量读取）
# 在 Colab 左边栏: ⚙ Settings → Secrets → 添加 HF_TOKEN
# 然后这里会自动读取
# ----------------------------


# ----------------------------
from transformers import AutoModelForCausalLM, AutoTokenizer
import pynvml, torch, time

# ----------------------------
# GPU 能耗监控
# ----------------------------
def init_nvml():
    pynvml.nvmlInit()
    return pynvml.nvmlDeviceGetHandleByIndex(0)

def get_power(handle):
    return pynvml.nvmlDeviceGetPowerUsage(handle) / 1000.0  # W


# ----------------------------
# 推理能耗测量 (快速版)
# ----------------------------
def measure_inference_fast(model_name, seq_len=128, n_samples=2):
    print(f"\n===== Running {model_name} (fast mode) =====")
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token

    # ✅ 半精度加载，减小显存占用
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        device_map="auto",
        torch_dtype=torch.bfloat16
    )
    model.eval()

    handle = init_nvml()
    total_energy, total_tokens = 0.0, 0

    for i in range(n_samples):
        text = "The quick brown fox jumps over the lazy dog."
        inputs = tokenizer(text, return_tensors="pt").to(model.device)

        power = get_power(handle)
        start = time.time()
        outputs = model.generate(**inputs, max_new_tokens=seq_len)
        duration = time.time() - start
        tokens = outputs.shape[1] - inputs["input_ids"].shape[1]

        energy = power * duration
        total_energy += energy
        total_tokens += tokens
        print(f"[{model_name}] Sample {i} | {tokens} tokens | {energy:.2f} J")

    avg_j_per_token = total_energy / total_tokens
    print(f"[{model_name}] Total: {total_tokens} tokens, {total_energy:.2f} J, {avg_j_per_token:.6f} J/token")

    return avg_j_per_token, total_tokens


# ----------------------------
# 跑 Mixtral-8x7B (MoE)
# ----------------------------
model_name = "mistralai/Mixtral-8x7B-Instruct-v0.1"
energy, tokens = measure_inference_fast(model_name)

print("\n===== Final Result =====")
print(f"Model: {model_name}, Energy/token: {energy:.6f} J, Tokens: {tokens}")